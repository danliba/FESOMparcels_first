{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2860e6a7-caed-4606-919a-76453976e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import xoak\n",
    "from matplotlib import pyplot as plt\n",
    "from cmocean import cm # for oceanography-specific colormaps\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "#import parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b5e09-dfa1-437a-a096-8d6a6b506545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%------------- Set the paths\n",
    "year = sys.argv[10]  # The tenth argument\n",
    "#mesh load\n",
    "mesh_file = os.path.join(path1, mesh_fn)\n",
    "#data load\n",
    "u_file = os.path.join(path1, f\"u.fesom.{year}.nc\")\n",
    "v_file = os.path.join(path1, f\"v.fesom.{year}.nc\")\n",
    "w_file = os.path.join(path1, f\"w.fesom.{year}.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0145f56c-f721-4729-b0ba-3bd6ef372607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%------------- Particles\n",
    "## Set the number of particles\n",
    "num_particles = int(sys.argv[1])\n",
    "\n",
    "## Set the location of the particles \n",
    "lon_start = np.random.uniform(2,3,size=(num_particles,)) \n",
    "lat_start = np.random.uniform(7.5, 12.5, size=(num_particles,))\n",
    "\n",
    "## set the tracking time\n",
    "days = int(sys.argv[2])\n",
    "minutes = 20\n",
    "\n",
    "## record the particles every timestep of\n",
    "hours=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51fd5a54-7f66-4dfd-a6ce-26da08931324",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mesh = xr.open_dataset(path1+mesh_fn)\n",
    "#now we define new coords\n",
    "ds_mesh = ds_mesh.assign_coords(\n",
    "    nod2=list(range(1, ds_mesh.sizes[\"nod2\"]+1)), \n",
    "    elem=list(range(1,ds_mesh.sizes['elem']+1)),\n",
    ")\n",
    "\n",
    "#corners\n",
    "elem_corner_lons = ds_mesh.lon.sel(nod2=ds_mesh.face_nodes)\n",
    "elem_corner_lats = ds_mesh.lat.sel(nod2=ds_mesh.face_nodes)\n",
    "\n",
    "max_elem_lon_range = 0.2\n",
    "tri_overlap=(elem_corner_lons.max('n3') - elem_corner_lons.min('n3')) > max_elem_lon_range\n",
    "\n",
    "near_channel_width =4\n",
    "channel_width = 4.5\n",
    "elem_corner_lons_unglued = xr.where(tri_overlap & (elem_corner_lons > near_channel_width), \n",
    "                                   elem_corner_lons - channel_width, elem_corner_lons)\n",
    "\n",
    "\n",
    "elem_center_lons_unglued = elem_corner_lons_unglued.mean('n3')\n",
    "elem_center_lats = elem_corner_lats.mean('n3')\n",
    "\n",
    "elem_center_lons = elem_corner_lons.mean('n3')\n",
    "\n",
    "## assign coordinates to the mesh\n",
    "ds_mesh = ds_mesh.assign_coords(\n",
    "    elem_center_lons=elem_center_lons_unglued,\n",
    "    elem_center_lats=elem_center_lats,\n",
    ")\n",
    "#nearest neighbour interpolation\n",
    "ds_mesh.xoak.set_index(['elem_center_lats','elem_center_lons'], 'sklearn_geo_balltree')\n",
    "\n",
    "channel_lon_bds = (0,4.5) # use inmutable objects\n",
    "channel_lat_bds = (0,18)\n",
    "number_lon = 2*72 \n",
    "number_lat = 2*292\n",
    "\n",
    "# w_lon = number_lon\n",
    "# w_lat = number_lat\n",
    "# w_lon = int(2*51.5)\n",
    "# w_lat = int(2*206)\n",
    "\n",
    "grid_lon = xr.DataArray(np.linspace(*channel_lon_bds,number_lon), \n",
    "                        dims=('grid_lon',))\n",
    "grid_lat = xr.DataArray(np.linspace(*channel_lat_bds,number_lat),\n",
    "                        dims=('grid_lat',))\n",
    "\n",
    "#reorder the lat and lon into a C grid\n",
    "target_lon, target_lat = xr.broadcast(grid_lon, grid_lat)\n",
    "\n",
    "#select the grid elements\n",
    "grid_elems = ds_mesh.xoak.sel(\n",
    "    elem_center_lats = target_lat,\n",
    "    elem_center_lons = target_lon,\n",
    ").elem\n",
    "\n",
    "grid_elems = grid_elems.assign_coords(\n",
    "    target_lat = target_lat,\n",
    "    target_lon = target_lon,\n",
    ")\n",
    "\n",
    "grid_elems = grid_elems.assign_coords(\n",
    "    grid_lat=grid_lat,\n",
    "    grid_lon=grid_lon,\n",
    ")\n",
    "\n",
    "## modify the mesh for nodes and \n",
    "ds_mesh = ds_mesh.assign_coords(\n",
    "    lat=(\"nod2\", ds_mesh.lat.data.flatten()),\n",
    "    lon=(\"nod2\", ds_mesh.lon.data.flatten()),\n",
    ")\n",
    "#\n",
    "# Ensure the xoak index \n",
    "ds_mesh.xoak.set_index([\"lat\", \"lon\"], \"sklearn_geo_balltree\")\n",
    "\n",
    "#-------------get the nod2grids\n",
    "#grid_nodes\n",
    "grid_nodes = ds_mesh.xoak.sel(\n",
    "    lat = target_lat,\n",
    "    lon = target_lon,\n",
    ").nod2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f363b5cf-8c6e-4c8c-bf25-07e579f75d7e",
   "metadata": {},
   "source": [
    "## Equal depth levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49cbd424-f7f4-4bd1-9e9b-f9b06e721ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'nz' (nz: 161)> Size: 1kB\n",
      "array([   0,    0,    9,    9,    9,    9,    9,   18,   18,   18,   18,\n",
      "         29,   29,   29,   41,   41,   41,   41,   55,   55,   55,   55,\n",
      "         69,   69,   69,   69,   85,   85,   85,   85,  103,  103,  103,\n",
      "        103,  122,  122,  122,  122,  144,  144,  144,  144,  144,  167,\n",
      "        167,  167,  193,  193,  193,  193,  221,  221,  221,  221,  252,\n",
      "        252,  252,  252,  252,  287,  287,  287,  287,  324,  324,  324,\n",
      "        324,  366,  366,  366,  412,  412,  412,  412,  462,  462,  462,\n",
      "        462,  517,  517,  517,  517,  578,  578,  578,  578,  578,  645,\n",
      "        645,  645,  718,  718,  718,  718,  799,  799,  799,  799,  888,\n",
      "        888,  888,  888,  986,  986,  986,  986,  986, 1094, 1094, 1094,\n",
      "       1212, 1212, 1212, 1212, 1343, 1343, 1343, 1343, 1486, 1486, 1486,\n",
      "       1486, 1644, 1644, 1644, 1644, 1644, 1817, 1817, 1817, 2008, 2008,\n",
      "       2008, 2008, 2008, 2218, 2218, 2218, 2449, 2449, 2449, 2449, 2703,\n",
      "       2703, 2703, 2703, 2982, 2982, 2982, 2982, 3290, 3290, 3290, 3290,\n",
      "       3628, 3628, 3628, 3628, 3628, 4000, 4000])\n",
      "Coordinates:\n",
      "  * nz       (nz) float64 1kB 0.0 0.0 9.038 9.038 ... 3.628e+03 4e+03 4e+03\n",
      "Attributes:\n",
      "    long_name:      depth of levels\n",
      "    standard_name:  \n",
      "    units:          meters\n",
      "    positive:       down\n",
      "<xarray.DataArray 'nz1' (nz1: 161)> Size: 1kB\n",
      "array([   4,    4,    4,    4,    4,   14,   14,   14,   14,   24,   24,\n",
      "         24,   24,   35,   35,   35,   35,   48,   48,   48,   48,   62,\n",
      "         62,   62,   62,   77,   77,   77,   77,   94,   94,   94,   94,\n",
      "        113,  113,  113,  113,  133,  133,  133,  133,  155,  155,  155,\n",
      "        155,  180,  180,  180,  180,  207,  207,  207,  207,  237,  237,\n",
      "        237,  237,  269,  269,  269,  269,  306,  306,  306,  306,  345,\n",
      "        345,  345,  345,  389,  389,  389,  389,  437,  437,  437,  437,\n",
      "        489,  489,  489,  489,  548,  548,  548,  548,  611,  611,  611,\n",
      "        611,  682,  682,  682,  682,  759,  759,  759,  759,  844,  844,\n",
      "        844,  844,  937,  937,  937,  937, 1040, 1040, 1040, 1040, 1153,\n",
      "       1153, 1153, 1153, 1278, 1278, 1278, 1278, 1414, 1414, 1414, 1414,\n",
      "       1565, 1565, 1565, 1565, 1731, 1731, 1731, 1731, 1913, 1913, 1913,\n",
      "       1913, 2113, 2113, 2113, 2113, 2333, 2333, 2333, 2333, 2576, 2576,\n",
      "       2576, 2576, 2843, 2843, 2843, 2843, 3136, 3136, 3136, 3136, 3459,\n",
      "       3459, 3459, 3459, 3814, 3814, 3814, 3814])\n",
      "Coordinates:\n",
      "  * nz1      (nz1) float64 1kB 4.519 4.519 4.519 ... 3.814e+03 3.814e+03\n",
      "Attributes:\n",
      "    long_name:  depth of layers\n",
      "    positive:   down\n"
     ]
    }
   ],
   "source": [
    "za = ds_mesh.nz.values #41\n",
    "zb = ds_mesh.nz1.values #40\n",
    "\n",
    "zc = np.array(sorted(np.concatenate((za, zb))))\n",
    "#print(zc)\n",
    "\n",
    "zg = np.sort(np.hstack((0.5 * (zc[0:-1] + zc[1:]), zc)))\n",
    "\n",
    "#nz grid \n",
    "nz_grid = ds_mesh.sel(nz = zg, method = 'nearest').nz\n",
    "print(nz_grid.astype(int))\n",
    "\n",
    "nz1_grid = ds_mesh.sel(nz1 = zg, method = 'nearest').nz1\n",
    "print(nz1_grid.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19879f1-0c9e-4ae6-9358-1c5574ec8021",
   "metadata": {},
   "source": [
    "## Load the data U,V,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e16961f-5219-4d54-b6a8-f1e0f109ba2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/xarray/core/dataset.py:282: UserWarning: The specified chunks separate the stored chunks along dimension \"nz1\" starting at index 1. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/xarray/core/dataset.py:282: UserWarning: The specified chunks separate the stored chunks along dimension \"nz1\" starting at index 1. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/xarray/core/dataset.py:282: UserWarning: The specified chunks separate the stored chunks along dimension \"nz\" starting at index 1. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds_u = xr.open_mfdataset(path1+u_path,\n",
    "                         chunks ={'time':1, 'nz1': 1})\n",
    "# first selecting only the surface nz1=0\n",
    "ds_v = xr.open_mfdataset(path1+v_path,\n",
    "                         chunks = {'time':1, 'nz1':1})\n",
    "\n",
    "ds_w = xr.open_mfdataset(path1+w_path,\n",
    "                         chunks = {'time':1, 'nz':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b34ea2-7424-4595-b7ea-be36113cc71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_grid = ds_u.u.isel(elem=grid_elems - 1).interp(nz1=nz1_grid,method = 'nearest') \n",
    "V_grid = ds_v.v.isel(elem=grid_elems - 1).interp(nz1=nz1_grid,method = 'nearest') \n",
    "W_grid = ds_w.w.isel(nod2=grid_nodes - 1).interp(nz=nz_grid,method = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de451b9-3879-4280-b3a4-975b67bcfec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(U_grid.shape)\n",
    "print(V_grid.shape)\n",
    "print(W_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec771d-045b-4a61-b890-00aa6dd60503",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_uv_grid= xr.Dataset({\n",
    "    'U':U_grid,\n",
    "    \"V\":V_grid,\n",
    "    \"W\":W_grid,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04598751-2e44-4900-a3dc-742ee2b31439",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_uv_grid\n",
    "## Keep only one Z and drop the other one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca51bf2-9808-4de2-95f4-a33aee7f3eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_uv_grid = ds_uv_grid.drop_vars('nz1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f38df7-b52f-43eb-9dd3-59ad8ee38e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_uv_grid['U'] = ds_uv_grid['U'].rename({'nz1':'nz'})\n",
    "ds_uv_grid['V'] = ds_uv_grid['V'].rename({'nz1':'nz'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12138b8-95f9-42c5-94a7-f0635f673d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_uv_grid = ds_uv_grid.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6091592b-e569-45f8-bb58-a72571684907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ds_uv_grid['U'].data.chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d6d9fc-62ce-4a4c-b0f6-b1c486be7ccd",
   "metadata": {},
   "source": [
    "## Now Parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff1d1bd-0bb8-4f00-b2f2-d0f112591d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parcels import ParticleSet\n",
    "from parcels import JITParticle\n",
    "from parcels import AdvectionRK4_3D\n",
    "from parcels import AdvectionRK4\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "from parcels import FieldSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc450c-f619-4e61-a789-1bc97ab9be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldset = FieldSet.from_xarray_dataset(\n",
    "    ds_uv_grid.transpose('time','nz','grid_lat','grid_lon'),\n",
    "    variables={'U':\"U\", \"V\":\"V\", \"W\":\"W\"},\n",
    "    dimensions={'lon':'grid_lon',\n",
    "                'lat':'grid_lat',\n",
    "                'depth':'nz',\n",
    "                'time':'time',\n",
    "               },\n",
    "    time_periodic=False,\n",
    "    allow_time_extrapolation=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1ff47-f6f3-4bc7-8dc2-6492e4526708",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_uv_grid.nz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f8a173-073a-40c9-aaa3-caa7498f53e3",
   "metadata": {},
   "source": [
    "## Halo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c39891-d6c1-4734-80f5-ee2a05c887ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldset.add_constant(\"halo_west\", fieldset.U.grid.lon[0])\n",
    "fieldset.add_constant(\"halo_east\", fieldset.U.grid.lon[-1])\n",
    "fieldset.add_periodic_halo(zonal=True)\n",
    "\n",
    "def periodicBC(particle,fielset,time):\n",
    "    if particle.lon < fieldset.halo_west:\n",
    "        particle_dlon += fieldset.halo_east - fieldset.halo_west\n",
    "    elif particle.lon > fieldset.halo_east:\n",
    "        particle_dlon -= fieldset.halo_east - fieldset.halo_west"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e2312-cbbe-4635-9dd0-7901bd2bf68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time and depth initial conditios\n",
    "time = np.repeat(ds_uv_grid.time[0].data, num_particles)  # Assign the same time to all particles\n",
    "depth = np.random.uniform(10,50, size=num_particles)  # Choose random depths\n",
    "#time = np.repeat(ds_uv_grid.time[0], num_particles)  # Assign the same time to all particles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaecedbb-58b4-4492-b069-c55b3291a917",
   "metadata": {},
   "source": [
    "## Initiate particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4e370-e03c-40fe-be2c-2fd9f4f617aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Init particle set\n",
    "pset = ParticleSet(\n",
    "    fieldset=fieldset,\n",
    "    pclass=JITParticle,\n",
    "    lon = lon_start,\n",
    "    lat = lat_start,\n",
    "    depth=depth,\n",
    "    time=time\n",
    ") \n",
    "\n",
    "# pset = parcels.ParticleSet.from_line(\n",
    "#     fieldset=fieldset,\n",
    "#     pclass=parcels.JITParticle,\n",
    "#     size=10,\n",
    "#     start=(1.9, 52.5),\n",
    "#     finish=(3.4, 51.6),\n",
    "#     depth=1,\n",
    "# )\n",
    "\n",
    "# lon = np.random.uniform(2, 3, size=num_particles)  # Longitudes between 2 and 3\n",
    "# lat = np.random.uniform(7.5, 12.5, size=num_particles)  # Latitudes between 7.5 and 12.5\n",
    "# depth = np.random.choice(ds_uv_grid.nz, size=num_particles)  # Choose random depths\n",
    "\n",
    "# lon_start = np.random.uniform(2,3,size=(num_particles,)) \n",
    "# lat_start = np.random.uniform(7.5, 12.5, size=(num_particles,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d05be-f6e9-4e62-b60f-69b5a408e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = pset.ParticleFile(name=out_path+out_fn, \n",
    "                                outputdt=timedelta(hours=hours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd144106-e4e5-4894-b84c-60c349818288",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute particles\n",
    "pset.execute(\n",
    "    [AdvectionRK4_3D,periodicBC],\n",
    "    runtime=timedelta(days=days),\n",
    "    dt=timedelta(minutes=minutes),\n",
    "    output_file= output_file\n",
    ")\n",
    "## check out a different advection squeme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deef477-5cbf-4b7f-ba7c-9cc4941a87f1",
   "metadata": {},
   "source": [
    "## Make a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7962317-a00c-410c-844a-5af3b7fcf4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import xoak\n",
    "from matplotlib import pyplot as plt\n",
    "from cmocean import cm # for oceanography-specific colormaps\n",
    "from itertools import zip_longest\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "from pathlib import Path\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d23777-af54-46a7-8651-312a0cc1f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_traj = xr.open_zarr(out_path+out_fn+\".zarr\")\n",
    "ds_traj = ds_traj.compute()\n",
    "ds_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f868f7-9758-4951-895d-74bf9a26d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_traj.isel(trajectory=5).z.plot(marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9c7056-77ae-4cc2-a9c6-c32a592ad74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre plot\n",
    "skip_this_step = abs(ds_traj.lon.diff('obs')) > 4.0\n",
    "ds_traj_nowrap = ds_traj.where(~skip_this_step)\n",
    "ds_traj_nowrap.isel(trajectory=0).to_pandas().plot.line(\n",
    "    x='lon', y='lat',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fee308-8bbf-4ca9-adc3-44df3cfaf74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_between(start,end):\n",
    "    \"\"\"Find the intermediate points on a line from (x0,y0) to (x1,y1).\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    start: tuple\n",
    "        Contains x0 and y0\n",
    "    end: tuple\n",
    "        Contains x1 and y1\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    list\n",
    "        List of all intermediate points (x,y)\n",
    "\n",
    "    \"\"\"\n",
    "    x0,y0 = start\n",
    "    x1,y1 = end\n",
    "    #This extracts the individual coordinates from the start and end tuples.\n",
    "    N = max(abs(x1 - x0) + 1, abs(y1 - y0) + 1) #calculate the number of steps\n",
    "    #Calculate the incremental step sizes\n",
    "    dx = (x1 - x0) / (N - 1) #for stepping in lon or x\n",
    "    dy = (y1 - y0) / (N - 1) #for stepping in lat or y\n",
    "    #the steps secure the evenly spaced points between the start and end\n",
    "\n",
    "    #Generate the intermediate points\n",
    "    xx = (round(x0 + n * dx) for n in range(N))\n",
    "    yy = (round(y0 + n * dy) for n in range(N))\n",
    "    #Combines the x and y coordinates into a list of tuples \n",
    "    return list(zip(xx,yy))\n",
    "\n",
    "def line_between_sequence(points):\n",
    "    \"\"\" Fill in lines on all segments of points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    points: list\n",
    "        List of points (x,y).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        List of points(x,y) with all segments filled in.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    segments = [\n",
    "    line_between(start,end)[:-1]\n",
    "    for start, end in zip(points[:-1], points[1:])\n",
    "    ] + [points[-1:], ]\n",
    "    return reduce(add, segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d1ce8-8f10-4aaf-b631-0e56ec60c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Unrolling\n",
    "ad_lon = 0 + 4.5 * (ds_traj.lon.diff('obs') < -4) - 4.5 * (ds_traj.lon.diff('obs') > 4)\n",
    "lon_unrolled = (ds_traj.lon + ad_lon.cumsum('obs')) #we accumulate the corrections \n",
    "lon_unrolled.isel(trajectory=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651a999-de41-4e74-a68f-04e9fbf14717",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx = 45 #~4.5\n",
    "Ny = 180 #~18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04230f15-7220-4137-966a-c6dc91d31e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each ghost image band corresponds to an increment of 4.5 longitude units.\n",
    "#Creates ghost images in left and right \n",
    "pix_replica_lon = lon_unrolled.min().compute().data[()] //4.5 , lon_unrolled.max().compute().data[()] //4.5 + 1\n",
    "pix_x_unrolled = np.arange(pix_replica_lon[0] * Nx, pix_replica_lon[1] * Nx).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1075bc-48b3-4dbc-bfb0-fce42c36cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_bds = (int(pix_replica_lon[0] *4.5), int(pix_replica_lon[1] * 4.5))\n",
    "lat_bds = (0,18)\n",
    "lon_bds, lat_bds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed50624b-5054-40ed-8e6c-7111ee9ed2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dens = np.zeros((Ny,Nx), dtype=int)\n",
    "\n",
    "for traj in tqdm.tqdm(ds_traj.trajectory.isel(trajectory=slice(None,None,1)).data):\n",
    "    lon_traj = lon_unrolled.sel(trajectory=traj).compute().data\n",
    "    lat_traj = ds_traj.lat.sel(trajectory=traj).compute().data\n",
    "    point_list = list(zip(\n",
    "        np.digitize(lon_traj, np.linspace(*lon_bds, int((pix_replica_lon[1] - pix_replica_lon[0]) * Nx))).astype(int)-1,\n",
    "        np.digitize(lat_traj, np.linspace(*lat_bds, Ny)).astype(int) -1,\n",
    "    ))\n",
    "\n",
    "    #drop the duplicates\n",
    "    point_list = [i for i, j in zip_longest(point_list, point_list[1:]) if i !=j]\n",
    "    pos,count = np.unique(np.array(line_between_sequence(point_list)), axis=0, return_counts = True)\n",
    "    #wrap back to Nx and Ny\n",
    "    pos = pos % [Nx,Ny]\n",
    "    dens[*pos.T[::-1]] +=count\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e3313-6486-4030-ae0d-b993231f6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_dpi(300)\n",
    "ax.imshow(dens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
